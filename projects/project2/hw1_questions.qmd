---
title: "A Replication of Karlan and List (2007)"
author: "Anoop Singh"
date: April 23, 2025
jupyter: env
callout-appearance: minimal
---


## Introduction

Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the _American Economic Review_ in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).

The matching grant letters varied along multiple dimensions, including the size of the match ($1:$1, $2:$1, or $3:$1), the maximum amount of the matching gift, and the suggested donation amount. These variations allowed the researchers to isolate the effects of perceived price changes and test whether more generous matches led to higher response rates or larger donation amounts. By embedding this experiment in a real fundraising campaign for a politically active nonprofit, the authors were able to gather behavioral data with high external validity.

This project seeks to replicate their results.


## Data

### Description

```{python}
import pandas as pd
import numpy as np
import statsmodels.formula.api as smf
import statsmodels.api as sm
from scipy import stats
import seaborn as sns
import matplotlib.pyplot as plt
import warnings

warnings.filterwarnings("ignore") # <-- just to make outputs look clean!

df = pd.read_stata("karlan_list_2007.dta")
df.head()
```
:::: {.callout-note collapse="true"}
### Variable Definitions

| Variable             | Description                                                         |
|----------------------|---------------------------------------------------------------------|
| `treatment`          | Treatment                                                           |
| `control`            | Control                                                             |
| `ratio`              | Match ratio                                                         |
| `ratio2`             | 2:1 match ratio                                                     |
| `ratio3`             | 3:1 match ratio                                                     |
| `size`               | Match threshold                                                     |
| `size25`             | \$25,000 match threshold                                            |
| `size50`             | \$50,000 match threshold                                            |
| `size100`            | \$100,000 match threshold                                           |
| `sizeno`             | Unstated match threshold                                            |
| `ask`                | Suggested donation amount                                           |
| `askd1`              | Suggested donation was highest previous contribution                |
| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |
| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |
| `ask1`               | Highest previous contribution (for suggestion)                      |
| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |
| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |
| `amount`             | Dollars given                                                       |
| `gave`               | Gave anything                                                       |
| `amountchange`       | Change in amount given                                              |
| `hpa`                | Highest previous contribution                                       |
| `ltmedmra`           | Small prior donor: last gift was less than median \$35              |
| `freq`               | Number of prior donations                                           |
| `years`              | Number of years since initial donation                              |
| `year5`              | At least 5 years since initial donation                             |
| `mrm2`               | Number of months since last donation                                |
| `dormant`            | Already donated in 2005                                             |
| `female`             | Female                                                              |
| `couple`             | Couple                                                              |
| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |
| `nonlit`             | Nonlitigation                                                       |
| `cases`              | Court cases from state in 2004-5 in which organization was involved |
| `statecnt`           | Percent of sample from state                                        |
| `stateresponse`      | Proportion of sample from the state who gave                        |
| `stateresponset`     | Proportion of treated sample from the state who gave                |
| `stateresponsec`     | Proportion of control sample from the state who gave                |
| `stateresponsetminc` | stateresponset - stateresponsec                                     |
| `perbush`            | State vote share for Bush                                           |
| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |
| `red0`               | Red state                                                           |
| `blue0`              | Blue state                                                          |
| `redcty`             | Red county                                                          |
| `bluecty`            | Blue county                                                         |
| `pwhite`             | Proportion white within zip code                                    |
| `pblack`             | Proportion black within zip code                                    |
| `page18_39`          | Proportion age 18-39 within zip code                                |
| `ave_hh_sz`          | Average household size within zip code                              |
| `median_hhincome`    | Median household income within zip code                             |
| `powner`             | Proportion house owner within zip code                              |
| `psch_atlstba`       | Proportion who finished college within zip code                     |
| `pop_propurban`      | Proportion of population urban within zip code                      |

::::


### Balance Test 

As an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.

```{python}
# Variables to test on
balance_vars = ['mrm2', 'hpa', 'freq']

for var in balance_vars:
    # Drop missing values
    group_A = df[df['treatment'] == 1][var].dropna()
    group_B = df[df['treatment'] == 0][var].dropna()
    
    # Compute means, stds, Ns for formula
    X_A, X_B = group_A.mean(), group_B.mean()
    S_A, S_B = group_A.std(ddof=1), group_B.std(ddof=1)
    N_A, N_B = len(group_A), len(group_B)
    
    # t-test using formula
    t_stat = (X_A - X_B) / np.sqrt((S_A**2 / N_A) + (S_B**2 / N_B))

    # Run OLS regression
    model = smf.ols(f"{var} ~ treatment", data=df).fit()
    coef = model.params['treatment']
    pval = model.pvalues['treatment']

    # Output
    print("\n" + "="*65)
    print(f"Balance test for: `{var}`")
    print(f"\nMean (Treatment): {X_A:.3f}, Mean (Control): {X_B:.3f}")
    print(f"t = {t_stat:.3f}")
    
    if abs(t_stat) > 1.96:
        print("The absolute t-statistic exceeds 1.96, indicating a statistically significant difference between treatment and control groups at the 5% level.")
    else:
        print("The absolute t-statistic is less than 1.96, suggesting no statistically significant difference between groups — balance is likely achieved.")

    print(f"\nRegression coefficient (treatment): {coef:.4f}, p-value: {pval:.3f}")
    if pval < 0.05:
        print(f"The p-value is less than 0.05 — this suggests imbalance for `{var}`.")
    else:
        print(f"The p-value is greater than 0.05 — no evidence of imbalance for `{var}`.")

```
:::: {.callout-note collapse="true"}
### OLS Tables
```{python}
balance_vars = ['mrm2', 'hpa', 'freq']

for var in balance_vars:
    print(f"### Full OLS Summary for `{var}`")
    print(model.summary())
    print(":::\n")
```
::::

## Experimental Results

### Charitable Contribution Made

First, I analyze whether matched donations lead to an increased response rate of making a donation. 

```{python}
# Prepare the data
donation_rate = df.groupby('treatment')['gave'].mean().reset_index()
donation_rate['group'] = donation_rate['treatment'].map({0: 'Control', 1: 'Treatment'})

# Plot
sns.set(style="whitegrid")
plt.figure(figsize=(6, 5))

ax = sns.barplot(x='group', y='gave', data=donation_rate, palette='Blues_d')

# Add labels on bars
for index, row in donation_rate.iterrows():
    ax.text(index, row['gave'] + 0.00001, f"{row['gave']:.2%}", ha='center', va='bottom', fontsize=12)

# Axis and title
ax.set_ylabel("Proportion Donated", fontsize=12)
ax.set_xlabel("")
ax.set_title("Donation Rates by Group", fontsize=14)
ax.set_ylim(0, 0.05)

plt.tight_layout()
plt.show()
```

```{python}
# Subset data for Regression and t-test
subset = df[(df['control'] == 1) | (df['treatment'] == 1)].copy()
subset['group'] = df['treatment']

# t-test
control_group = subset[subset['group'] == 0]['gave']
treat_group = subset[subset['group'] == 1]['gave']

# Use stats library instead of manual formula
t_stat, p_val = stats.ttest_ind(treat_group, control_group, equal_var=False)

print("\n=== T-Test: Treatment vs Control ===")
print(f"Control response rate: {control_group.mean():.3f}")
print(f"Treatment response rate: {treat_group.mean():.3f}")
print(f"t-statistic: {t_stat:.3f}")
print(f"p-value: {p_val:.4f}")

# Regression
model = smf.ols("gave ~ group", data=subset).fit()

# Print results
print("\n=== OLS Regression Summary ===")
print(model.summary())
```

In this regression, I found that people in the treatment group were significantly more likely to donate compared to those in the control group. The increase in donation likelihood is small, but the result is statistically significant, meaning it is unlikely to be due to random chance. This is shown by the p-value of 0.002 for the treatment variable, which is well below the common 0.05 threshold for significance. The coefficient of 0.0042 means that the treatment increased the probability of donating by about 0.42 percentage points. Even though most people did not donate overall, being told their gift would be matched made a small but noticeable difference.

```{python}
# Probit Model
probit_model = smf.probit("gave ~ treatment", data=df).fit()
print(probit_model.summary())
print("\n")

# Marginal effect of Probit Model (to show 0.004!)
mfx = probit_model.get_margeff(at='mean')
print(mfx.summary())
```

I also ran a Probit regression to estimate the effect of being in the treatment group on the likelihood of donating. The marginal effect of treatment is about 0.0043, meaning that receiving the matching message increased the probability of donating by 0.43 percentage points. This effect is statistically significant with a p-value of 0.002, suggesting the treatment had a real impact on behavior, even if the absolute increase was small. This result further solidifies the results found from the T-Test and the logistic regression.

### Differences between Match Rates

Next, I assess the effectiveness of different sizes of matched donations on the response rate. In their paper, Karlan and List say “Yet, while the match treatments relative to a control group increase the probability of donating, larger match ratios—$3:$1 and $2:$1—relative to smaller match ratios ($1:$1) had no additional impact.” This was a surprising conclusion to me, so I tested the differences between match rates below.

```{python}
# Filter only those with a ratio value
ratio_df = df[df['ratio'].notna()]

# Create groups for each ratio level
group_1_1 = ratio_df[ratio_df['ratio'] == 1]['gave']
group_2_1 = ratio_df[ratio_df['ratio'] == 2]['gave']
group_3_1 = ratio_df[ratio_df['ratio'] == 3]['gave']

# Run t-tests using stats
t_21_vs_11, p_21_vs_11 = stats.ttest_ind(group_2_1, group_1_1, equal_var=False)
t_31_vs_11, p_31_vs_11 = stats.ttest_ind(group_3_1, group_1_1, equal_var=False)
t_31_vs_21, p_31_vs_21 = stats.ttest_ind(group_3_1, group_2_1, equal_var=False)

# Print results
print("\n=== T-Tests: Match Ratio Comparisons ===")
print(f"2:1 vs 1:1 — t = {t_21_vs_11:.3f}, p = {p_21_vs_11:.4f}")
print(f"3:1 vs 1:1 — t = {t_31_vs_11:.3f}, p = {p_31_vs_11:.4f}")
print(f"3:1 vs 2:1 — t = {t_31_vs_21:.3f}, p = {p_31_vs_21:.4f}")
```

The t-tests showed no statistically significant differences between the groups (all p-values > 0.05), indicating that larger match ratios did not significantly increase the probability of donating. These results support the authors’ claim that, although announcing a match increases giving, increasing the match size (from 1:1 to 2:1 or 3:1) has no further effect. Interesting!

```{python}
# Make ratio1
df['ratio1'] = (df['ratio'] == 1).astype(int)

# Filter to just treatment group with non-null ratio values
subset = df[df['ratio'].notna()].copy()

# Run the regression with 1:1 as the baseline
model = smf.ols("gave ~ ratio1 + ratio2 + ratio3 - 1", data=subset).fit()
print(model.summary())
```

To further validate this claim, I created a new variable (ratio1), representing a 1:1 match. I then used it along with ratio2 and ratio3 in a regression, taking out the intercept to avoid multicollinearity. The estimated donation rates were 2.07% for the 1:1 match group, 2.26% for the 2:1 group, and 2.27% for the 3:1 group. While the differences are statistically significant due to the large sample size, they are extremely small in magnitude. This supports the authors’ finding that increasing the match ratio beyond 1:1 does not meaningfully increase donation likelihood.

### Size of Charitable Contribution

In this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.

```{python}
# Compare the amount donated for EVERYONE
treat_group = df[df['treatment'] == 1]['amount'].dropna()
control_group = df[df['control'] == 1]['amount'].dropna()

# Run t-tests using stats
t_stat, p_val = stats.ttest_ind(treat_group, control_group, equal_var=False)

# Print results
print("=== T-Test: Amount Donated ~ Treatment ===")
print(f"Mean (Control): {control_group.mean():.3f}")
print(f"Mean (Treatment): {treat_group.mean():.3f}")
print(f"t-statistic: {t_stat:.3f}")
print(f"p-value: {p_val:.4f}")
```

I ran both a t-test to compare the average donation amount between the treatment and control groups. The treatment group gave slightly more on average, and the difference was statistically significant. However, the increase was modest in size. This tells us that while being in the treatment group (with a matching grant) not only increases the likelihood of donating, it also slightly increases how much people give — suggesting that matching grants may influence both whether and how much people donate.

```{python}
# Now compare amounts donated only considering people who donated
donated_df = df[(df['gave'] == 1) & ((df['treatment'] == 1) | (df['control'] == 1))].copy()
donated_df['group'] = donated_df['treatment']  # 1 if treatment, 0 if control

# Find donation amounts
treat_amt = donated_df[donated_df['group'] == 1]['amount']
control_amt = donated_df[donated_df['group'] == 0]['amount']

# Run t-test using stats
t_stat, p_val = stats.ttest_ind(treat_amt, control_amt, equal_var=False)

# Print results
print("=== T-Test: Amount (Conditional on Giving) ===")
print(f"Mean (Treatment): {treat_amt.mean():.2f}")
print(f"Mean (Control): {control_amt.mean():.2f}")
print(f"t-statistic: {t_stat:.3f}")
print(f"p-value: {p_val:.4f}")
```

I examined whether people in the treatment group donated more money than those in the control group, conditional on having donated. The average donation amount was slightly lower in the treatment group ($43.87) than in the control group ($45.54), but this difference was not statistically significant (p = 0.559). This suggests that while the treatment increased the likelihood of giving, it did not affect how much people gave once they decided to donate. Since this analysis is limited to those who self-selected into giving, the treatment coefficient does not have a clear causal interpretation — the act of giving may already differ across groups due to unobserved selection.

```{python}
# Filter for people who donated
donors = df[(df['gave'] == 1) & ((df['control'] == 1) | (df['treatment'] == 1))].copy()
donors['group'] = donors['treatment'].map({0: 'Control', 1: 'Treatment'})

# Create plot
sns.set(style="whitegrid")

# Create subplots
fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)

# Plot histogram for each group
for i, grp in enumerate(['Control', 'Treatment']):
    data = donors[donors['group'] == grp]['amount']
    mean_val = data.mean()
    
    sns.histplot(data, bins=30, ax=axes[i], kde=False, color='skyblue')
    axes[i].axvline(mean_val, color='red', linestyle='--', label=f'Mean = ${mean_val:.2f}')
    axes[i].set_title(f"{grp} Group")
    axes[i].set_xlabel("Donation Amount")
    axes[i].set_ylabel("Number of Donors")
    axes[i].legend()

plt.suptitle("Donation Amounts (Among Donors Only)", fontsize=14)
plt.tight_layout()
plt.show()
```

## Simulation Experiment

As a reminder of how the t-statistic "works," in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.

Suppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made. 

Further suppose that the true distribution of respondents who do get a charitable donation match of any size  is Bernoulli with probability p=0.022 that a donation is made.

### Law of Large Numbers

```{python}
# Set true values
p_control = 0.018
p_treatment = 0.022

# Simulate data
np.random.seed(1234)
control = np.random.binomial(1, p_control, size=100_000)
treatment = np.random.binomial(1, p_treatment, size=10_000)

# Compute the difference in each simulation
differences = treatment - control[:10_000]

# Compute the cumulative average of differences
cum_avg = np.cumsum(differences) / np.arange(1, len(differences) + 1)

# Plot
plt.figure(figsize=(10, 5))
plt.plot(cum_avg, label='Cumulative Average Difference')
plt.axhline(0.004, color='red', linestyle='--', label='True Difference (0.004)')
plt.xlabel('Number of Observations')
plt.ylabel('Cumulative Average Difference')
plt.title('Law of Large Numbers: Cumulative Avg of Treatment − Control')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
```

The plot shows the cumulative average difference in donation outcomes between a simulated treatment group (with p = 0.022) and control group (p = 0.018), across 10,000 samples. Even though the average is very volatile at first, as the number of observations increases, the cumulative average stabilizes and converges toward the true difference of 0.004. This is the Law of Large Numbers! With enough observations, the sample average converges to the expected value and shows the true effect of the treatment.

### Central Limit Theorem

_to do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the "middle" of the distribution or whether it's in the "tail."_

```{python}
# Set true values
p_control = 0.018
p_treatment = 0.022
n_simulations = 1000
sample_sizes = [50, 200, 500, 1000]

np.random.seed(1234)

# Set up the plots
fig, axes = plt.subplots(2, 2, figsize=(12, 8))
axes = axes.flatten()

# Run simulation for each sample size
for i, n in enumerate(sample_sizes):
    diffs = []
    for _ in range(n_simulations):
        control = np.random.binomial(1, p_control, size=n)
        treatment = np.random.binomial(1, p_treatment, size=n)
        diffs.append(treatment.mean() - control.mean())
    
    # Plot histogram of average differences
    sns.histplot(diffs, bins=30, kde=False, ax=axes[i], color='skyblue')
    axes[i].axvline(0.004, color='red', linestyle='--', label='True Diff = 0.004')
    axes[i].axvline(0, color='black', linestyle=':', label='Zero')
    axes[i].set_title(f"Sample Size = {n}")
    axes[i].set_xlabel("Difference in Means")
    axes[i].set_ylabel("Frequency")
    axes[i].legend()

plt.tight_layout()
plt.suptitle("Sampling Distribution of Differences at Varying Sample Sizes", fontsize=14, y=1.02)
plt.show()
```

These histograms show the sampling distributions of the difference in donation rates between treatment and control groups at different sample sizes (50, 200, 500, 1000). As the sample size increases, the distribution becomes narrower (less variation) and increasingly centers around the true treatment effect of 0.004. At small sample sizes, the distribution is wide and zero is often near the center, meaning we might not detect a treatment effect. But at larger sample sizes, the distribution shifts away from zero, and it becomes clear that the treatment increases donation probability. This highlights how statistical significance depends not just on effect size, but also on sample size.

## Conclusion

This analysis explored how subtle changes in charitable fundraising messages can influence donor behavior. Across a range of statistical tests and simulations, the results consistently showed that while offering a matching donation increases the likelihood that someone donates, increasing the match ratio beyond a basic 1:1 offer provides little additional benefit. The treatment’s effect was primarily observed in encouraging people to give, rather than changing how much they donated. These findings highlight the importance of behavioral nudges in shaping economic decisions, the role of sample size in detecting effects, and the value of empirical evidence in challenging fundraising assumptions. Thank you for stopping by!